import numpy as np
X = np.array(([1,3],[4,7],[6,10]))
y = np.array(([90],[80],[98]))
y = y / 100

def sig(n):
    return 1/(1 + np.exp(-n))
def der(n):
    return n * (1 - n)

epoch = 1
lr = 0.1
inputlayer_neurons = 2
hiddenLayer_neurons = 3
output_layer = 1

wh = np.random.uniform(size=(inputlayer_neurons, hiddenLayer_neurons))
bias_hidden =np.random.uniform(size=(1, hiddenLayer_neurons))

weight_hidden = np.random.uniform(size=(hiddenLayer_neurons, output_layer))
bias_output = np.random.uniform(size=(1, output_layer))

print(weight_hidden, "W")
print(weight_hidden.T,"WT")

for i in range(epoch):
    hinp1 = np.dot(X, wh)
    hinp = hinp1 + bias_hidden
    hlayer_activation = sig(hinp)
    
    outinp1 = np.dot(hlayer_activation, weight_hidden)
    outinp = outinp1 + bias_output
    output = sig(outinp)
    
    EO = y - output
    outgrad = der(output)
    d_output = EO * outgrad
    
    EH = d_output.dot(weight_hidden.T)
    hiddengrad = der(hlayer_activation)
    d_hiddenlayer = EH * hiddengrad
    
    weight_hidden += hlayer_activation.T.dot(d_output) * lr
    bias_hidden += np.sum(d_hiddenlayer, axis = 0, keepdims = True) * lr
    
    wh += X.T.dot(d_hiddenlayer) * lr
    bias_output += np.sum(d_output, axis = 0, keepdims = True) * lr
    
print("Input:\n", str(X))
print("Actual output:\n", str(y))
print("Output:\n", output)
